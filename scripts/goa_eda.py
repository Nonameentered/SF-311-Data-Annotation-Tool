#!/usr/bin/env python3
from __future__ import annotations
import argparse
from datetime import datetime, timezone
from pathlib import Path
from typing import List
import pandas as pd
import re

try:
    import matplotlib.pyplot as plt  # type: ignore
except ImportError:  # pragma: no cover
    plt = None

GOA_REGEX = re.compile(r"(?:unable to locate|gone on arrival|\bgoa\b)", re.IGNORECASE)


def rel_to_docs(path: Path) -> str:
    docs_root = Path("docs").resolve()
    try:
        rel = path.resolve().relative_to(docs_root)
        return f"../{rel.as_posix()}"
    except ValueError:
        return path.as_posix()


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Generate exploratory summaries for responder GOA analysis."
    )
    parser.add_argument(
        "--input",
        default="data/derived/goa_features.parquet",
        help="Prepared GOA feature dataset (default: data/derived/goa_features.parquet).",
    )
    parser.add_argument(
        "--report-dir",
        default="data/reports",
        help="Directory to store tabular outputs (default: data/reports).",
    )
    parser.add_argument(
        "--doc",
        default="docs/goa_eda.md",
        help="Markdown file to overwrite with autogenerated commentary.",
    )
    parser.add_argument(
        "--asset-dir",
        default=None,
        help="Optional directory for plots (defaults to report-dir).",
    )
    parser.add_argument(
        "--top-notes",
        type=int,
        default=10,
        help="Number of top status note buckets to surface (default: 10).",
    )
    return parser.parse_args()


def read_dataset(path: Path) -> pd.DataFrame:
    if not path.exists():
        raise FileNotFoundError(f"GOA features dataset not found: {path}")
    suffix = path.suffix.lower()
    if suffix == ".parquet":
        return pd.read_parquet(path)
    if suffix in {".jsonl", ".json"}:
        return pd.read_json(path, lines=True)
    if suffix == ".csv":
        return pd.read_csv(path)
    raise ValueError(f"Unsupported input format: {path}")


def ensure_dir(path: Path) -> None:
    path.mkdir(parents=True, exist_ok=True)


def df_to_markdown_table(df: pd.DataFrame, float_cols: List[str] | None = None) -> str:
    float_cols = float_cols or []
    headers = list(df.columns)
    lines = ["| " + " | ".join(headers) + " |"]
    lines.append("| " + " | ".join(["---"] * len(headers)) + " |")
    for _, row in df.iterrows():
        values = []
        for col in headers:
            val = row[col]
            if col in float_cols and pd.notna(val):
                values.append(f"{val:.2f}")
            else:
                values.append(str(val))
        lines.append("| " + " | ".join(values) + " |")
    return "\n".join(lines)


def maybe_bar_plot(
    x: List[str], y: List[float], title: str, ylabel: str, output_path: Path
) -> bool:
    if plt is None:
        return False
    output_path.parent.mkdir(parents=True, exist_ok=True)
    plt.figure(figsize=(8, 4.5))
    plt.bar(x, y)
    plt.xticks(rotation=45, ha="right")
    plt.ylabel(ylabel)
    plt.title(title)
    plt.tight_layout()
    plt.grid(axis="y", alpha=0.2)
    plt.savefig(output_path, dpi=150)
    plt.close()
    return True


def format_percentage(numerator: int, denominator: int) -> float:
    return (numerator / denominator * 100.0) if denominator else 0.0


def clean_category(series: pd.Series, fallback: str = "Unknown") -> pd.Series:
    return series.fillna(fallback).astype(str).str.strip().replace("", fallback)


def generate_summaries(df: pd.DataFrame, top_notes: int) -> dict:
    total_rows = len(df)
    goa_count = int(df["responder_goa"].sum())
    goa_pct = format_percentage(goa_count, total_rows)
    missing_notes = int(df["status_notes"].isna().sum())

    status_col = clean_category(df.get("status"), "Unknown")
    status_counts = (
        status_col.value_counts(dropna=False)
        .rename_axis("status")
        .rename("count")
        .reset_index()
    )
    status_counts["share_pct"] = status_counts["count"].apply(
        lambda c: format_percentage(c, total_rows)
    )

    status_goa = (
        df.assign(status=status_col)["status"]
        .to_frame()
        .assign(responder_goa=df["responder_goa"])
        .groupby("status")["responder_goa"]
        .agg(["count", "sum"])
        .rename(columns={"count": "total", "sum": "goa_count"})
        .reset_index()
    )
    status_goa["goa_rate_pct"] = status_goa.apply(
        lambda row: format_percentage(row["goa_count"], row["total"]), axis=1
    )
    status_goa = status_goa.sort_values(by="goa_rate_pct", ascending=False)

    status_notes_clean = clean_category(df.get("status_notes_clean"), "Unknown")
    top_status_notes = (
        status_notes_clean.value_counts()
        .rename_axis("status_note")
        .rename("count")
        .reset_index()
        .head(top_notes)
    )
    top_status_notes["share_pct"] = top_status_notes["count"].apply(
        lambda c: format_percentage(c, total_rows)
    )

    goa_by_status_note = (
        df.assign(status_note=status_notes_clean)
        .groupby("status_note")["responder_goa"]
        .agg(["count", "sum"])
        .rename(columns={"count": "total", "sum": "goa_count"})
        .reset_index()
        .sort_values(by="total", ascending=False)
        .head(top_notes)
    )
    goa_by_status_note["goa_rate_pct"] = goa_by_status_note.apply(
        lambda row: format_percentage(row["goa_count"], row["total"]), axis=1
    )

    status_notes_split = (
        df.assign(status_note=status_notes_clean, responder_goa=df["responder_goa"])
        .groupby(["status_note", "responder_goa"])
        .size()
        .reset_index(name="count")
        .sort_values("count", ascending=False)
    )

    top_status_notes_non_goa = (
        status_notes_split[status_notes_split["responder_goa"] == False]
        .head(top_notes)
        .copy()
    )
    top_status_notes_non_goa["share_pct"] = top_status_notes_non_goa["count"].apply(
        lambda c: format_percentage(c, total_rows)
    )

    goa_status_notes = status_notes_split[
        status_notes_split["responder_goa"] == True
    ].copy()
    goa_status_notes["share_pct"] = goa_status_notes["count"].apply(
        lambda c: format_percentage(c, total_rows)
    )
    goa_regex_candidates = goa_status_notes[
        ~goa_status_notes["status_note"].str.contains(GOA_REGEX, na=False)
    ].copy()

    column_summary_rows = []
    for col in df.columns:
        series = df[col]
        non_null = int(series.notna().sum())
        nulls = int(series.isna().sum())
        try:
            unique_val = series.nunique(dropna=True)
            unique = int(unique_val)
        except TypeError:
            unique = None
        column_summary_rows.append(
            {
                "column": col,
                "dtype": str(series.dtype),
                "non_null": non_null,
                "nulls": nulls,
                "completeness_pct": format_percentage(non_null, total_rows),
                "unique_values": unique,
            }
        )
    column_summary = pd.DataFrame(column_summary_rows).sort_values(
        by=["nulls", "column"], ascending=[False, True]
    )

    def build_value_table(columns: List[str]) -> pd.DataFrame:
        rows = []
        for col in columns:
            series = df[col]
            counts = series.fillna("NULL").value_counts(dropna=False)
            for value, count in counts.items():
                rows.append(
                    {
                        "column": col,
                        "value": value,
                        "count": int(count),
                        "share_pct": format_percentage(int(count), total_rows),
                    }
                )
        return pd.DataFrame(rows)

    keyword_cols = [c for c in df.columns if c.startswith("kw_")]
    tag_cols = [c for c in df.columns if c.startswith("tag_")]
    derived_cols = [c for c in df.columns if c.startswith("derived_")]

    keyword_distribution = build_value_table(keyword_cols) if keyword_cols else pd.DataFrame()
    tag_distribution = build_value_table(tag_cols) if tag_cols else pd.DataFrame()
    derived_distribution = build_value_table(derived_cols) if derived_cols else pd.DataFrame()

    status_notes_distribution = (
        status_notes_clean.value_counts()
        .rename_axis("status_note")
        .rename("count")
        .reset_index()
    )
    status_notes_distribution["share_pct"] = status_notes_distribution["count"].apply(
        lambda c: format_percentage(c, total_rows)
    )

    has_photo_counts = (
        df["has_photo"]
        .value_counts(dropna=False)
        .rename_axis("has_photo")
        .rename("count")
        .reset_index()
    )
    has_photo_counts["share_pct"] = has_photo_counts["count"].apply(
        lambda c: format_percentage(c, total_rows)
    )

    police_district_counts = (
        clean_category(df.get("police_district"), "Unknown")
        .value_counts()
        .rename_axis("police_district")
        .rename("count")
        .reset_index()
    )
    police_district_counts["share_pct"] = police_district_counts["count"].apply(
        lambda c: format_percentage(c, total_rows)
    )

    hours_to_resolution_stats = df["hours_to_resolution"].describe().to_frame(name="hours_to_resolution").reset_index()

    return {
        "total_rows": total_rows,
        "goa_count": goa_count,
        "goa_pct": goa_pct,
        "missing_notes": missing_notes,
        "status_counts": status_counts,
        "status_goa": status_goa,
        "top_status_notes": top_status_notes,
        "goa_by_status_note": goa_by_status_note,
        "column_summary": column_summary,
        "keyword_distribution": keyword_distribution,
        "tag_distribution": tag_distribution,
        "derived_distribution": derived_distribution,
        "status_notes_distribution": status_notes_distribution,
        "has_photo_counts": has_photo_counts,
        "police_district_counts": police_district_counts,
        "hours_to_resolution_stats": hours_to_resolution_stats,
        "top_status_notes_non_goa": top_status_notes_non_goa,
        "goa_status_notes": goa_status_notes,
        "goa_regex_candidates": goa_regex_candidates,
    }


def write_reports(summary: dict, report_dir: Path) -> None:
    ensure_dir(report_dir)
    summary_table = pd.DataFrame(
        [
            {
                "total_rows": summary["total_rows"],
                "responder_goa": summary["goa_count"],
                "responder_goa_pct": summary["goa_pct"],
                "missing_status_notes": summary["missing_notes"],
            }
        ]
    )
    summary_table.to_csv(report_dir / "goa_overview.csv", index=False)
    summary["status_counts"].to_csv(
        report_dir / "goa_status_distribution.csv", index=False
    )
    summary["status_goa"].to_csv(report_dir / "goa_status_goa_rates.csv", index=False)
    summary["top_status_notes"].to_csv(
        report_dir / "goa_top_status_notes.csv", index=False
    )
    summary["goa_by_status_note"].to_csv(
        report_dir / "goa_status_note_goa_rates.csv", index=False
    )
    summary["top_status_notes_non_goa"].to_csv(
        report_dir / "goa_top_status_notes_non_goa.csv", index=False
    )
    summary["goa_status_notes"].to_csv(
        report_dir / "goa_status_notes_goa_only.csv", index=False
    )
    summary["goa_regex_candidates"].to_csv(
        report_dir / "goa_status_notes_regex_candidates.csv", index=False
    )
    summary["column_summary"].to_csv(
        report_dir / "goa_column_completeness.csv", index=False
    )
    summary["status_notes_distribution"].to_csv(
        report_dir / "goa_status_notes_distribution.csv", index=False
    )
    if not summary["keyword_distribution"].empty:
        summary["keyword_distribution"].to_csv(
            report_dir / "goa_keyword_distribution.csv", index=False
        )
    if not summary["tag_distribution"].empty:
        summary["tag_distribution"].to_csv(
            report_dir / "goa_tag_distribution.csv", index=False
        )
    if not summary["derived_distribution"].empty:
        summary["derived_distribution"].to_csv(
            report_dir / "goa_derived_distribution.csv", index=False
        )
    summary["has_photo_counts"].to_csv(
        report_dir / "goa_has_photo_distribution.csv", index=False
    )
    summary["police_district_counts"].to_csv(
        report_dir / "goa_police_district_distribution.csv", index=False
    )
    summary["hours_to_resolution_stats"].to_csv(
        report_dir / "goa_hours_to_resolution_stats.csv", index=False
    )


def build_markdown(
    summary: dict, artifacts: List[tuple[str, str]], plots: List[tuple[str, str]]
) -> str:
    generated_at = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%SZ")
    total_rows = summary["total_rows"]
    goa_count = summary["goa_count"]
    goa_pct = summary["goa_pct"]
    missing_notes = summary["missing_notes"]

    raw_column_summary = summary["column_summary"]
    empty_columns = raw_column_summary.loc[
        raw_column_summary["completeness_pct"] == 0, "column"
    ].tolist()
    partial_columns = raw_column_summary.loc[
        (raw_column_summary["completeness_pct"] > 0)
        & (raw_column_summary["completeness_pct"] < 100)
    ]["column"].head(5)
    partial_columns_list = partial_columns.tolist()

    raw_has_photo = summary["has_photo_counts"]
    has_photo_true_share = None
    if not raw_has_photo.empty:
        true_rows = raw_has_photo[raw_has_photo["has_photo"].isin([True, "True", 1])]
        if not true_rows.empty:
            has_photo_true_share = true_rows["share_pct"].iloc[0]

    column_summary_display = summary["column_summary"].head(10).copy()
    column_summary_display["non_null"] = column_summary_display["non_null"].map(
        lambda x: f"{int(x):,}"
    )
    column_summary_display["nulls"] = column_summary_display["nulls"].map(
        lambda x: f"{int(x):,}"
    )
    column_summary_display["unique_values"] = column_summary_display["unique_values"].map(
        lambda x: f"{int(x):,}" if isinstance(x, (int, float)) and pd.notna(x) else "n/a"
    )
    column_summary_display = column_summary_display[
        [
            "column",
            "dtype",
            "non_null",
            "nulls",
            "completeness_pct",
            "unique_values",
        ]
    ]

    keyword_true = summary["keyword_distribution"]
    if not keyword_true.empty:
        keyword_true = keyword_true[
            keyword_true["value"].isin([True, "True", 1])
        ].copy()
        keyword_true["count"] = keyword_true["count"].map(lambda x: f"{int(x):,}")

    tag_true = summary["tag_distribution"]
    if not tag_true.empty:
        tag_true = tag_true[tag_true["value"].isin([True, "True", 1])].copy()
        tag_true["count"] = tag_true["count"].map(lambda x: f"{int(x):,}")

    derived_table = summary["derived_distribution"]
    if not derived_table.empty:
        derived_table = derived_table[derived_table["value"].isin([True, "True", 1])].copy()
        derived_table["count"] = derived_table["count"].map(lambda x: f"{int(x):,}")

    has_photo_table = summary["has_photo_counts"].copy()
    has_photo_table["count"] = has_photo_table["count"].map(lambda x: f"{int(x):,}")

    police_table = summary["police_district_counts"].copy()
    police_table["count"] = police_table["count"].map(lambda x: f"{int(x):,}")

    top_status_notes_non_goa = summary["top_status_notes_non_goa"].copy()
    if not top_status_notes_non_goa.empty:
        if "responder_goa" in top_status_notes_non_goa.columns:
            top_status_notes_non_goa = top_status_notes_non_goa.drop(
                columns=["responder_goa"]
            )
        top_status_notes_non_goa["count"] = top_status_notes_non_goa["count"].map(
            lambda x: f"{int(x):,}"
        )

    goa_regex_candidates = summary["goa_regex_candidates"].copy()
    if not goa_regex_candidates.empty:
        if "responder_goa" in goa_regex_candidates.columns:
            goa_regex_candidates = goa_regex_candidates.drop(columns=["responder_goa"])
        goa_regex_candidates["count"] = goa_regex_candidates["count"].map(
            lambda x: f"{int(x):,}"
        )

    hours_stats = summary["hours_to_resolution_stats"].copy()
    hours_stats["hours_to_resolution"] = hours_stats["hours_to_resolution"].map(
        lambda x: f"{x:.2f}"
    )
    hours_stats = hours_stats.rename(columns={"index": "metric"})

    md_lines = [
        "# GOA Exploratory Overview",
        "",
        f"_Auto-generated on {generated_at}. Update this file after reviewing the outputs._",
        "",
        "## Dataset Snapshot",
        f"- Total requests: **{total_rows:,}**",
        f"- Responder GOA cases: **{goa_count:,}** ({goa_pct:.2f}%)",
        f"- Missing responder status notes: **{missing_notes:,}**",
        "",
        "## Responder Status Distribution",
        "",
        df_to_markdown_table(
            summary["status_counts"].assign(
                count=summary["status_counts"]["count"].map(lambda x: f"{int(x):,}")
            ),
            float_cols=["share_pct"],
        ),
        "",
        "### GOA Rate by Status",
        "",
        df_to_markdown_table(
            summary["status_goa"].assign(
                total=summary["status_goa"]["total"].map(lambda x: f"{int(x):,}"),
                goa_count=summary["status_goa"]["goa_count"].map(
                    lambda x: f"{int(x):,}"
                ),
            ),
            float_cols=["goa_rate_pct"],
        ),
        "",
        "### Top Status Notes",
        "",
        df_to_markdown_table(
            summary["top_status_notes"].assign(
                count=summary["top_status_notes"]["count"].map(
                    lambda x: f"{int(x):,}"
                )
            ),
            float_cols=["share_pct"],
        ),
        "",
        "### GOA Rate by Status Note (Top Buckets)",
        "",
        df_to_markdown_table(
            summary["goa_by_status_note"].assign(
                total=summary["goa_by_status_note"]["total"].map(
                    lambda x: f"{int(x):,}"
                ),
                goa_count=summary["goa_by_status_note"]["goa_count"].map(
                    lambda x: f"{int(x):,}"
                ),
            ),
            float_cols=["goa_rate_pct"],
        ),
        "",
    ]
    if not top_status_notes_non_goa.empty:
        md_lines.extend(
            [
                "### Top Status Notes (Non-GOA Closures)",
                "",
                df_to_markdown_table(
                    top_status_notes_non_goa[
                        ["status_note", "count", "share_pct"]
                    ],
                    float_cols=["share_pct"],
                ),
                "",
            ]
        )
    else:
        md_lines.extend(
            [
                "### Top Status Notes (Non-GOA Closures)",
                "",
                "No non-GOA status notes recorded.",
                "",
            ]
        )
    if not column_summary_display.empty:
        md_lines.extend(
            [
                "## Column Completeness (Top 10 Missing Fields)",
                "",
                df_to_markdown_table(
                    column_summary_display, float_cols=["completeness_pct"]
                ),
                "",
            ]
        )
    if not has_photo_table.empty:
        md_lines.extend(
            [
                "## Has Photo Coverage",
                "",
                df_to_markdown_table(
                    has_photo_table, float_cols=["share_pct"]
                ),
                "",
            ]
        )
    if not police_table.empty:
        md_lines.extend(
            [
                "## Police District Distribution",
                "",
                df_to_markdown_table(
                    police_table, float_cols=["share_pct"]
                ),
                "",
            ]
        )
    if not keyword_true.empty:
        md_lines.extend(
            [
                "## Keyword Coverage (True Rates)",
                "",
                df_to_markdown_table(
                    keyword_true[["column", "count", "share_pct"]],
                    float_cols=["share_pct"],
                ),
                "",
            ]
        )
    if not tag_true.empty:
        md_lines.extend(
            [
                "## Tag Coverage (True Rates)",
                "",
                df_to_markdown_table(
                    tag_true[["column", "count", "share_pct"]],
                    float_cols=["share_pct"],
                ),
                "",
            ]
        )
    if not derived_table.empty:
        md_lines.extend(
            [
                "## Derived Indicators (True Rates)",
                "",
                df_to_markdown_table(
                    derived_table[["column", "count", "share_pct"]],
                    float_cols=["share_pct"],
                ),
                "",
            ]
        )
    if not hours_stats.empty:
        md_lines.extend(
            [
                "## Hours to Resolution Summary",
                "",
                df_to_markdown_table(hours_stats, float_cols=None),
                "",
            ]
        )
    if not goa_regex_candidates.empty:
        md_lines.extend(
            [
                "## GOA Status Notes Outside Current Regex",
                "",
                df_to_markdown_table(
                    goa_regex_candidates[["status_note", "count", "share_pct"]],
                    float_cols=["share_pct"],
                ),
                "",
            ]
        )

    auto_commentary = [
        "## Auto Commentary",
        f"- GOA makes up **{goa_pct:.2f}%** of all requests in this snapshot.",
        "- The distribution table above highlights how GOA cases are concentrated within specific responder statuses; review the counts before drawing conclusions.",
        "- High shares of \"Unable to Locate\" or similar notes may reflect recording practices as much as field conditions—interpret rates with caution.",
    ]
    if empty_columns:
        auto_commentary.append(
            "- Fields with 0% completeness: `" + ", ".join(empty_columns) + "` (likely placeholders)."
        )
    if partial_columns_list:
        auto_commentary.append(
            "- Partially complete fields worth tracking: `"
            + ", ".join(partial_columns_list)
            + "`."
        )
    if has_photo_true_share is not None:
        auto_commentary.append(
            f"- Photos accompany about {has_photo_true_share:.2f}% of requests, so visual evidence is common but not universal."
        )
    if not goa_regex_candidates.empty:
        candidate_examples = ", ".join(
            goa_regex_candidates["status_note"].head(3).tolist()
        )
        auto_commentary.append(
            "- Consider expanding the GOA regex to cover notes like: "
            + candidate_examples
            + (" ..." if len(goa_regex_candidates) > 3 else "")
        )
    auto_commentary.append("")
    auto_commentary.extend(
        [
            "## Analyst Notes (edit me)",
            "- TODO: Add context, field insights, or follow-up questions here.",
        ]
    )
    md_lines.extend(auto_commentary)

    if plots:
        md_lines.extend(["", "## Quick Visuals", ""])
        for rel_path, desc in plots:
            md_lines.append(f"![{desc}]({rel_path})")
            md_lines.append("")

    if artifacts:
        md_lines.extend(["", "## Generated Artifacts", ""])
        for rel_path, desc in artifacts:
            md_lines.append(f"- `{rel_path}` – {desc}")

    return "\n".join(md_lines)


def write_markdown(doc_path: Path, content: str) -> None:
    doc_path.parent.mkdir(parents=True, exist_ok=True)
    doc_path.write_text(content, encoding="utf-8")


def main() -> None:
    args = parse_args()
    input_path = Path(args.input)
    report_dir = Path(args.report_dir)
    doc_path = Path(args.doc)

    df = read_dataset(input_path)
    summary = generate_summaries(df, top_notes=args.top_notes)
    write_reports(summary, report_dir)

    asset_dir = Path(args.asset_dir) if args.asset_dir else report_dir
    asset_dir.mkdir(parents=True, exist_ok=True)
    plot_entries: List[tuple[str, str]] = []

    status_counts = summary["status_counts"].sort_values("count", ascending=False)
    status_plot = asset_dir / "goa_status_distribution.png"
    if maybe_bar_plot(
        status_counts["status"].tolist(),
        status_counts["count"].tolist(),
        "Responder status distribution",
        "Count",
        status_plot,
    ):
        plot_entries.append((rel_to_docs(status_plot), "Responder status distribution"))

    top_notes = summary["top_status_notes"]
    top_notes_plot = asset_dir / "goa_top_status_notes.png"
    if not top_notes.empty and maybe_bar_plot(
        top_notes["status_note"].tolist(),
        top_notes["share_pct"].tolist(),
        "Top responder status notes",
        "Share (%)",
        top_notes_plot,
    ):
        plot_entries.append((rel_to_docs(top_notes_plot), "Top responder status notes"))

    top_notes_non_goa = summary["top_status_notes_non_goa"]
    non_goa_plot = asset_dir / "goa_top_status_notes_non_goa.png"
    if not top_notes_non_goa.empty and maybe_bar_plot(
        top_notes_non_goa["status_note"].tolist(),
        top_notes_non_goa["share_pct"].tolist(),
        "Top non-GOA status notes",
        "Share (%)",
        non_goa_plot,
    ):
        plot_entries.append((rel_to_docs(non_goa_plot), "Top non-GOA status notes"))

    has_photo = summary["has_photo_counts"]
    has_photo_plot = asset_dir / "goa_has_photo.png"
    if not has_photo.empty and maybe_bar_plot(
        has_photo["has_photo"].astype(str).tolist(),
        has_photo["share_pct"].tolist(),
        "Photo coverage",
        "Share (%)",
        has_photo_plot,
    ):
        plot_entries.append((rel_to_docs(has_photo_plot), "Photo coverage share"))

    police_counts = summary["police_district_counts"].head(10)
    police_plot = asset_dir / "goa_police_district.png"
    if not police_counts.empty and maybe_bar_plot(
        police_counts["police_district"].tolist(),
        police_counts["share_pct"].tolist(),
        "Police district mix (top 10)",
        "Share (%)",
        police_plot,
    ):
        plot_entries.append((rel_to_docs(police_plot), "Police district mix (top 10)"))

    raw_artifacts = [
        (report_dir / "goa_overview.csv", "Global counts and overall GOA rate"),
        (report_dir / "goa_status_distribution.csv", "Responder status counts"),
        (report_dir / "goa_status_goa_rates.csv", "GOA rate by responder status"),
        (report_dir / "goa_top_status_notes.csv", "Top responder status notes"),
        (report_dir / "goa_status_note_goa_rates.csv", "GOA rate by top responder status notes"),
        (report_dir / "goa_top_status_notes_non_goa.csv", "Top responder status notes excluding GOA outcomes"),
        (report_dir / "goa_status_notes_goa_only.csv", "Responder status notes for GOA cases"),
        (report_dir / "goa_status_notes_regex_candidates.csv", "GOA status notes not matched by current regex"),
        (report_dir / "goa_status_notes_distribution.csv", "Full responder status-note distribution"),
        (report_dir / "goa_column_completeness.csv", "Column completeness summary"),
        (report_dir / "goa_keyword_distribution.csv", "Reporter keyword flag distribution"),
        (report_dir / "goa_tag_distribution.csv", "Reporter tag distribution"),
        (report_dir / "goa_derived_distribution.csv", "Derived indicator distribution"),
        (report_dir / "goa_has_photo_distribution.csv", "Photo coverage split"),
        (report_dir / "goa_police_district_distribution.csv", "Police district counts"),
        (report_dir / "goa_hours_to_resolution_stats.csv", "Hours-to-resolution descriptive stats"),
        (asset_dir / "goa_status_distribution.png", "Responder status bar chart"),
        (asset_dir / "goa_top_status_notes.png", "Top responder status notes chart"),
        (asset_dir / "goa_top_status_notes_non_goa.png", "Top non-GOA status notes chart"),
        (asset_dir / "goa_has_photo.png", "Photo coverage chart"),
        (asset_dir / "goa_police_district.png", "Police district mix chart"),
    ]

    artifact_entries = []
    for path, desc in raw_artifacts:
        if path.exists():
            artifact_entries.append((rel_to_docs(path), desc))

    markdown = build_markdown(summary, artifact_entries, plot_entries)
    write_markdown(doc_path, markdown)

    print(f"[goa-eda] wrote tables to {report_dir}")
    print(f"[goa-eda] refreshed {doc_path}")


if __name__ == "__main__":
    main()
def rel_to_docs(path: Path) -> str:
    docs_root = Path("docs").resolve()
    try:
        rel = path.resolve().relative_to(docs_root)
        return f"../{rel.as_posix()}"
    except ValueError:
        return path.as_posix()
