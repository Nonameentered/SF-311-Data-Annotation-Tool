#!/usr/bin/env python3
from __future__ import annotations
import argparse
from datetime import datetime, timezone
from pathlib import Path
from typing import Iterable, List
import numpy as np
import pandas as pd


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Generate temporal GOA rates and resolution-time summaries."
    )
    parser.add_argument(
        "--input",
        default="data/derived/goa_features.parquet",
        help="Prepared GOA feature dataset (default: data/derived/goa_features.parquet).",
    )
    parser.add_argument(
        "--report-dir",
        default="data/reports",
        help="Directory to store output tables/plots (default: data/reports).",
    )
    parser.add_argument(
        "--doc",
        default="docs/goa_trends.md",
        help="Markdown file to overwrite with autogenerated commentary.",
    )
    parser.add_argument(
        "--bins",
        default="0,1,3,6,12,24,48,96,168",
        help="Comma-separated hour thresholds for resolution histograms (last bin is open-ended).",
    )
    parser.add_argument(
        "--rolling-window",
        type=int,
        default=7,
        help="Rolling window (days) for daily GOA rate smoothing.",
    )
    parser.add_argument(
        "--preview-days",
        type=int,
        default=14,
        help="Number of most recent daily rows to show in Markdown tables.",
    )
    return parser.parse_args()


def read_dataset(path: Path) -> pd.DataFrame:
    if not path.exists():
        raise FileNotFoundError(f"GOA features dataset not found: {path}")
    suffix = path.suffix.lower()
    if suffix == ".parquet":
        return pd.read_parquet(path)
    if suffix in {".jsonl", ".json"}:
        return pd.read_json(path, lines=True)
    if suffix == ".csv":
        return pd.read_csv(path)
    raise ValueError(f"Unsupported input format: {path}")


def ensure_dir(path: Path) -> None:
    path.mkdir(parents=True, exist_ok=True)


def parse_bins(bin_str: str) -> List[float]:
    if not bin_str:
        return [0, 1, 3, 6, 12, 24, 48, 96, 168]
    values = []
    for part in bin_str.split(","):
        try:
            values.append(float(part.strip()))
        except ValueError:
            continue
    values = sorted(set(values))
    if 0.0 not in values:
        values.insert(0, 0.0)
    return values


def compute_daily_rates(df: pd.DataFrame, rolling_window: int) -> pd.DataFrame:
    df = df.copy()
    df["created_at_dt"] = pd.to_datetime(df["created_at"], errors="coerce")
    df = df.dropna(subset=["created_at_dt"])
    df["created_date"] = df["created_at_dt"].dt.date
    grouped = (
        df.groupby("created_date")["responder_goa"]
        .agg(["count", "sum"])
        .rename(columns={"count": "total", "sum": "goa_count"})
        .reset_index()
        .sort_values("created_date")
    )
    grouped["goa_rate"] = grouped["goa_count"] / grouped["total"]
    if rolling_window > 1:
        grouped["goa_rate_roll"] = (
            grouped["goa_rate"].rolling(window=rolling_window, min_periods=1).mean()
        )
    else:
        grouped["goa_rate_roll"] = grouped["goa_rate"]
    return grouped


def compute_weekly_rates(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["created_at_dt"] = pd.to_datetime(df["created_at"], errors="coerce")
    df = df.dropna(subset=["created_at_dt"])
    df["week_start"] = (
        df["created_at_dt"].dt.to_period("W-MON").dt.start_time.dt.tz_localize(None)
    )
    grouped = (
        df.groupby("week_start")["responder_goa"]
        .agg(["count", "sum"])
        .rename(columns={"count": "total", "sum": "goa_count"})
        .reset_index()
        .sort_values("week_start")
    )
    grouped["goa_rate"] = grouped["goa_count"] / grouped["total"]
    return grouped


def compute_resolution_hist(
    df: pd.DataFrame, bins: Iterable[float]
) -> pd.DataFrame:
    df = df.copy()
    df["hours_to_resolution"] = pd.to_numeric(df["hours_to_resolution"], errors="coerce")
    df["responder_goa_flag"] = df["responder_goa"].astype(bool)
    bin_edges = list(bins)
    if not np.isinf(bin_edges[-1]):
        bin_edges.append(np.inf)
    labels = []
    for i in range(len(bin_edges) - 1):
        start = bin_edges[i]
        end = bin_edges[i + 1]
        if np.isinf(end):
            labels.append(f"{start:.0f}+")
        else:
            labels.append(f"{start:.0f}-{end:.0f}")
    results = []
    for goa_flag, subset in df.groupby("responder_goa_flag"):
        hist, edges = np.histogram(
            subset["hours_to_resolution"].dropna(), bins=bin_edges
        )
        total = int(hist.sum())
        for label, count in zip(labels, hist):
            share = (count / total * 100.0) if total else 0.0
            results.append(
                {
                    "responder_goa": goa_flag,
                    "bin_label": label,
                    "count": int(count),
                    "share_pct": share,
                    "total": total,
                }
            )
    return pd.DataFrame(results)


def compute_resolution_stats(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["hours_to_resolution"] = pd.to_numeric(df["hours_to_resolution"], errors="coerce")
    stats = (
        df.groupby("responder_goa")["hours_to_resolution"]
        .describe()
        .reset_index()
        .rename(columns={"responder_goa": "responder_goa_flag"})
    )
    return stats


def df_to_markdown_table(df: pd.DataFrame, float_cols: List[str] | None = None) -> str:
    float_cols = float_cols or []
    headers = list(df.columns)
    lines = ["| " + " | ".join(headers) + " |"]
    lines.append("| " + " | ".join(["---"] * len(headers)) + " |")
    for _, row in df.iterrows():
        values = []
        for col in headers:
            val = row[col]
            if col in float_cols and pd.notna(val):
                values.append(f"{val:.2f}")
            else:
                values.append(str(val))
        lines.append("| " + " | ".join(values) + " |")
    return "\n".join(lines)


def build_markdown(
    daily: pd.DataFrame,
    weekly: pd.DataFrame,
    hist: pd.DataFrame,
    stats: pd.DataFrame,
    preview_days: int,
    rolling_window: int,
    artifacts: List[tuple[str, str]],
    data_horizon_note: str | None,
) -> str:
    generated_at = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%SZ")
    recent_daily = daily.tail(preview_days).copy()
    recent_daily["goa_rate_pct"] = recent_daily["goa_rate"] * 100.0
    recent_daily["goa_rate_roll_pct"] = recent_daily["goa_rate_roll"] * 100.0
    recent_daily["created_date"] = recent_daily["created_date"].astype(str)
    recent_daily["total"] = recent_daily["total"].map(lambda x: f"{int(x):,}")
    recent_daily["goa_count"] = recent_daily["goa_count"].map(lambda x: f"{int(x):,}")

    weekly_preview = weekly.tail(12).copy()
    weekly_preview["week_start"] = weekly_preview["week_start"].astype(str)
    weekly_preview["total"] = weekly_preview["total"].map(lambda x: f"{int(x):,}")
    weekly_preview["goa_count"] = weekly_preview["goa_count"].map(
        lambda x: f"{int(x):,}"
    )
    weekly_preview["goa_rate_pct"] = weekly_preview["goa_rate"] * 100.0

    hist_display = hist.copy()
    hist_display["count"] = hist_display["count"].map(lambda x: f"{int(x):,}")

    stats_display = stats.copy()
    stats_display["responder_goa_flag"] = stats_display["responder_goa_flag"].map(
        {True: "GOA", False: "Non-GOA"}
    )

    md_lines = [
        "# GOA Temporal & Resolution Summary",
        "",
        f"_Auto-generated on {generated_at}. Rolling window: {rolling_window} days._",
        "",
        "## Daily GOA Rates (Most Recent)",
        "",
        df_to_markdown_table(
            recent_daily[
                [
                    "created_date",
                    "total",
                    "goa_count",
                    "goa_rate_pct",
                    "goa_rate_roll_pct",
                ]
            ],
            float_cols=["goa_rate_pct", "goa_rate_roll_pct"],
        ),
        "",
        "## Weekly GOA Rates (Most Recent)",
        "",
        df_to_markdown_table(
            weekly_preview[["week_start", "total", "goa_count", "goa_rate_pct"]],
            float_cols=["goa_rate_pct"],
        ),
        "",
        "## Hours to Resolution Histogram",
        "",
        df_to_markdown_table(
            hist_display[["responder_goa", "bin_label", "count", "share_pct", "total"]],
            float_cols=["share_pct"],
        ),
        "",
        "## Hours to Resolution Descriptive Stats",
        "",
        df_to_markdown_table(stats_display, float_cols=None),
        "",
        "## Auto Commentary",
    ]

    if not daily.empty:
        latest = daily.iloc[-1]
        md_lines.append(
            f"- Latest day ({latest['created_date']}): GOA rate {latest['goa_rate']*100:.2f}% "
            f"across {int(latest['total']):,} requests."
        )
    if "goa_rate_roll" in daily.columns:
        md_lines.append(
            f"- {rolling_window}-day rolling GOA rate currently averages "
            f"{daily['goa_rate_roll'].iloc[-1]*100:.2f}%."
        )
    if not weekly.empty:
        md_lines.append(
            f"- Weekly counts range from {int(weekly['total'].min()):,} to "
            f"{int(weekly['total'].max()):,}; GOA rate spans "
            f"{weekly['goa_rate'].min()*100:.2f}%–{weekly['goa_rate'].max()*100:.2f}%."
        )
    goa_hist_total = hist.loc[hist["responder_goa"] == True, "total"].max()
    non_hist_total = hist.loc[hist["responder_goa"] == False, "total"].max()
    if goa_hist_total and non_hist_total:
        md_lines.append(
            f"- GOA cases ({goa_hist_total:,} with resolution timestamps) skew "
            f"toward the lowest bins; compare against {non_hist_total:,} non-GOA rows."
        )
    if data_horizon_note:
        md_lines.append(f"- {data_horizon_note}")
    md_lines.append(
        "- Inspect underlying CSVs in `data/reports/` for full history and charting."
    )
    md_lines.extend(
        [
            "",
            "## Analyst Notes (edit me)",
            "- TODO: Add temporal context, staffing notes, or follow-up questions.",
        ]
    )
    if artifacts:
        md_lines.extend(["", "## Generated Artifacts", ""])
        for rel_path, desc in artifacts:
            md_lines.append(f"- `{rel_path}` – {desc}")
    return "\n".join(md_lines)


def main() -> None:
    args = parse_args()
    input_path = Path(args.input)
    report_dir = Path(args.report_dir)
    doc_path = Path(args.doc)
    bins = parse_bins(args.bins)

    df = read_dataset(input_path)
    daily = compute_daily_rates(df, rolling_window=args.rolling_window)
    weekly = compute_weekly_rates(df)
    hist = compute_resolution_hist(df, bins=bins)
    stats = compute_resolution_stats(df)

    ensure_dir(report_dir)
    daily.to_csv(report_dir / "goa_daily_rates.csv", index=False)
    weekly.to_csv(report_dir / "goa_weekly_rates.csv", index=False)
    hist.to_csv(report_dir / "goa_resolution_hours_hist.csv", index=False)
    stats.to_csv(report_dir / "goa_resolution_hours_stats.csv", index=False)

    artifact_entries = [
        ("data/reports/goa_daily_rates.csv", "Daily GOA counts and rates"),
        ("data/reports/goa_weekly_rates.csv", "Weekly GOA counts and rates"),
        (
            "data/reports/goa_resolution_hours_hist.csv",
            "Resolution-time histogram bins by GOA flag",
        ),
        (
            "data/reports/goa_resolution_hours_stats.csv",
            "Resolution-time descriptive statistics",
        ),
    ]
    artifact_entries = [entry for entry in artifact_entries if Path(entry[0]).exists()]

    data_horizon_note = None
    if not daily.empty:
        latest_date = pd.to_datetime(daily["created_date"].iloc[-1])
        today = datetime.now(timezone.utc).date()
        delta = (today - latest_date.date()).days
        if delta <= 2:
            data_horizon_note = (
                "Latest daily data is "
                f"{delta} day{'s' if delta != 1 else ''} old (" + str(latest_date.date()) + "); "
                "rates near the cutoff may change as more records arrive."
            )

    doc_content = build_markdown(
        daily=daily,
        weekly=weekly,
        hist=hist,
        stats=stats,
        preview_days=args.preview_days,
        rolling_window=args.rolling_window,
        artifacts=artifact_entries,
        data_horizon_note=data_horizon_note,
    )
    doc_path.parent.mkdir(parents=True, exist_ok=True)
    doc_path.write_text(doc_content, encoding="utf-8")

    print(f"[goa-trends] wrote tables to {report_dir}")
    print(f"[goa-trends] refreshed {doc_path}")


if __name__ == "__main__":
    main()
