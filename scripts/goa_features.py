#!/usr/bin/env python3
from __future__ import annotations
import argparse
from datetime import datetime, timezone
from pathlib import Path
from typing import Iterable, List, Optional, Tuple

import numpy as np
import pandas as pd

try:
    import matplotlib.pyplot as plt  # type: ignore
except ImportError:  # pragma: no cover
    plt = None

import sys

CURRENT_DIR = Path(__file__).resolve().parent
if str(CURRENT_DIR) not in sys.path:
    sys.path.append(str(CURRENT_DIR))

from goa_labels import FEATURE_LABELS
def rel_to_docs(path: Path) -> str:
    docs_root = Path("docs").resolve()
    try:
        rel = path.resolve().relative_to(docs_root)
        return f"../{rel.as_posix()}"
    except ValueError:
        return path.as_posix()

TRUE_LIKE = {"true", "1", "yes", "y", "t"}


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Compute GOA correlations for binary and numeric features."
    )
    parser.add_argument(
        "--input",
        default="data/derived/goa_features.parquet",
        help="Prepared GOA dataset (default: data/derived/goa_features.parquet).",
    )
    parser.add_argument(
        "--report-dir",
        default="data/reports",
        help="Directory for output CSVs/plots (default: data/reports).",
    )
    parser.add_argument(
        "--doc",
        default="docs/goa_features.md",
        help="Markdown file to overwrite with autogenerated commentary.",
    )
    parser.add_argument(
        "--top-n",
        type=int,
        default=10,
        help="How many positive/negative signals to highlight (default: 10).",
    )
    parser.add_argument(
        "--asset-dir",
        default=None,
        help="Optional directory for plots (defaults to report-dir).",
    )
    return parser.parse_args()


def read_dataset(path: Path) -> pd.DataFrame:
    if not path.exists():
        raise FileNotFoundError(f"GOA features dataset not found: {path}")
    suffix = path.suffix.lower()
    if suffix == ".parquet":
        return pd.read_parquet(path)
    if suffix in {".jsonl", ".json"}:
        return pd.read_json(path, lines=True)
    if suffix == ".csv":
        return pd.read_csv(path)
    raise ValueError(f"Unsupported input format: {path}")


def ensure_dir(path: Path) -> None:
    path.mkdir(parents=True, exist_ok=True)


def to_bool(series: pd.Series) -> pd.Series:
    if pd.api.types.is_bool_dtype(series):
        return series.fillna(False)
    if pd.api.types.is_numeric_dtype(series):
        return series.fillna(0).astype(float).ne(0)
    lowered = series.astype(str).str.strip().str.lower()
    return lowered.isin(TRUE_LIKE)


def summarize_binary_features(
    df: pd.DataFrame, columns: Iterable[str], target: str
) -> pd.DataFrame:
    records: List[dict] = []
    global_rate = df[target].mean()
    total_rows = len(df)

    for col in columns:
        if col not in df.columns:
            continue
        bool_series = to_bool(df[col])
        for value_label, mask in (("True", bool_series), ("False", ~bool_series)):
            count = int(mask.sum())
            if count == 0:
                continue
            goa_count = int(df.loc[mask, target].sum())
            goa_rate = goa_count / count
            delta = goa_rate - global_rate if pd.notna(goa_rate) else np.nan
            share_pct = count / total_rows * 100 if total_rows else 0.0
            record = {
                "feature": col,
                "value": value_label,
                "count": count,
                "goa_count": goa_count,
                "goa_rate_pct": goa_rate * 100 if pd.notna(goa_rate) else np.nan,
                "delta_pp": delta * 100 if pd.notna(delta) else np.nan,
                "share_pct": share_pct,
            }
            records.append(record)

        # odds ratio for True vs False on separate pass
        true_mask = bool_series
        false_mask = ~bool_series
        true_pos = df.loc[true_mask, target].sum()
        true_neg = true_mask.sum() - true_pos
        false_pos = df.loc[false_mask, target].sum()
        false_neg = false_mask.sum() - false_pos
        # add 0.5 smoothing to avoid division by zero
        odds_ratio = (
            (true_pos + 0.5) * (false_neg + 0.5) / ((true_neg + 0.5) * (false_pos + 0.5))
            if (true_mask.sum() > 0 and false_mask.sum() > 0)
            else np.nan
        )
        # annotate existing rows if they were appended
        true_rows_idx = [
            idx for idx, rec in enumerate(records) if rec["feature"] == col and rec["value"] == "True"
        ]
        false_rows_idx = [
            idx for idx, rec in enumerate(records) if rec["feature"] == col and rec["value"] == "False"
        ]
        if true_rows_idx:
            records[true_rows_idx[-1]]["odds_ratio"] = odds_ratio
        if false_rows_idx:
            records[false_rows_idx[-1]]["odds_ratio"] = np.nan

    df = pd.DataFrame(records)
    df["label"] = df["feature"].map(FEATURE_LABELS).fillna(df["feature"])
    return df


def summarize_numeric_bins(
    df: pd.DataFrame,
    column: str,
    bins: List[float],
    labels: Optional[List[str]],
    target: str,
) -> pd.DataFrame:
    series = pd.to_numeric(df[column], errors="coerce")
    cat = pd.cut(series, bins=bins, labels=labels, include_lowest=True, right=False)
    result = (
        df.assign(bin_label=cat)
        .groupby("bin_label", observed=False)[target]
        .agg(["count", "sum"])
        .rename(columns={"sum": "goa_count"})
        .reset_index()
    )
    result["feature"] = column
    result["goa_rate_pct"] = result["goa_count"] / result["count"] * 100
    total = len(df)
    result["share_pct"] = result["count"] / total * 100 if total else 0.0

    # Add explicit row for missing values
    missing_mask = cat.isna()
    if missing_mask.any():
        count = int(missing_mask.sum())
        goa_count = int(df.loc[missing_mask, target].sum())
        goa_rate = goa_count / count * 100 if count else np.nan
        missing_row = {
            "bin_label": "Missing",
            "count": count,
            "goa_count": goa_count,
            "feature": column,
            "goa_rate_pct": goa_rate,
            "share_pct": count / total * 100 if total else 0.0,
        }
        result = pd.concat([result, pd.DataFrame([missing_row])], ignore_index=True)
    return result


def df_to_markdown_table(df: pd.DataFrame, float_cols: List[str] | None = None) -> str:
    float_cols = float_cols or []
    headers = list(df.columns)
    lines = ["| " + " | ".join(headers) + " |"]
    lines.append("| " + " | ".join(["---"] * len(headers)) + " |")
    for _, row in df.iterrows():
        values = []
        for col in headers:
            val = row[col]
            if col in float_cols and pd.notna(val):
                values.append(f"{val:.2f}")
            else:
                values.append(str(val))
        lines.append("| " + " | ".join(values) + " |")
    return "\n".join(lines)


def maybe_bar_plot(
    feats: pd.DataFrame,
    title: str,
    output_path: Path,
    value_col: str = "delta_pp",
) -> bool:
    if plt is None or feats.empty:
        return False
    output_path.parent.mkdir(parents=True, exist_ok=True)
    plt.figure(figsize=(8, 4.5))
    plt.bar(feats["feature"], feats[value_col])
    plt.xticks(rotation=45, ha="right")
    ylabel = "Î” GOA rate (pp)" if value_col == "delta_pp" else "GOA rate (%)"
    plt.ylabel(ylabel)
    plt.title(title)
    plt.tight_layout()
    plt.grid(axis="y", alpha=0.2)
    plt.savefig(output_path, dpi=150)
    plt.close()
    return True


def build_markdown(
    binary_df: pd.DataFrame,
    numeric_df: pd.DataFrame,
    global_rate: float,
    top_n: int,
    artifacts: List[Tuple[str, str]],
    plots: List[Tuple[str, str]],
) -> str:
    generated_at = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%SZ")
    global_pct = global_rate * 100

    true_rows = binary_df[binary_df["value"] == "True"].copy()
    true_rows = true_rows.sort_values("delta_pp", ascending=False)
    top_positive = true_rows.head(top_n)
    top_negative = true_rows.tail(top_n).sort_values("delta_pp")

    md_lines = [
        "# GOA Feature Signals",
        "",
        f"_Auto-generated on {generated_at}. Overall GOA rate: {global_pct:.2f}%._",
        "",
        "## Top Positive Indicators (True rows)",
        "",
        df_to_markdown_table(
            top_positive[
                [
                    "feature",
                    "count",
                    "goa_count",
                    "goa_rate_pct",
                    "delta_pp",
                    "odds_ratio",
                ]
            ],
            float_cols=["goa_rate_pct", "delta_pp", "odds_ratio"],
        )
        if not top_positive.empty
        else "No positive indicators identified.",
        "",
        "## Largest Negative Deltas (True rows)",
        "",
        df_to_markdown_table(
            top_negative[
                [
                    "feature",
                    "count",
                    "goa_count",
                    "goa_rate_pct",
                    "delta_pp",
                    "odds_ratio",
                ]
            ],
            float_cols=["goa_rate_pct", "delta_pp", "odds_ratio"],
        )
        if not top_negative.empty
        else "No negative indicators identified.",
        "",
    ]

    for feature_name, subset in numeric_df.groupby("feature"):
        md_lines.extend(
            [
                f"## {feature_name} bins",
                "",
                df_to_markdown_table(
                    subset[
                        [
                            "bin_label",
                            "count",
                            "goa_count",
                            "goa_rate_pct",
                            "share_pct",
                        ]
                    ],
                    float_cols=["goa_rate_pct", "share_pct"],
                ),
                "",
            ]
        )

    md_lines.extend(
        [
            "## Auto Commentary",
            f"- Overall responder GOA rate is {global_pct:.2f}%.",
        ]
    )
    if not top_positive.empty:
        md_lines.append(
            "- Strongest positive signal: "
            f"`{top_positive.iloc[0]['feature']}` (Î” {top_positive.iloc[0]['delta_pp']:.2f} pp)."
        )
    if not top_negative.empty:
        md_lines.append(
            "- Strongest negative signal: "
            f"`{top_negative.iloc[0]['feature']}` (Î” {top_negative.iloc[0]['delta_pp']:.2f} pp)."
        )
    md_lines.append("")

    if plots:
        md_lines.extend(["## Quick Visuals", ""])
        for rel_path, desc in plots:
            md_lines.append(f"![{desc}]({rel_path})")
            md_lines.append("")

    md_lines.extend(
        [
            "## Analyst Notes (edit me)",
            "- TODO: Add interpretation of feature signals or follow-up actions.",
        ]
    )
    if artifacts:
        md_lines.extend(["", "## Generated Artifacts", ""])
        for rel_path, desc in artifacts:
            md_lines.append(f"- `{rel_path}` â€“ {desc}")
    return "\n".join(md_lines)


def main() -> None:
    args = parse_args()
    input_path = Path(args.input)
    report_dir = Path(args.report_dir)
    doc_path = Path(args.doc)

    df = read_dataset(input_path)
    ensure_dir(report_dir)
    asset_dir = Path(args.asset_dir) if args.asset_dir else report_dir
    asset_dir.mkdir(parents=True, exist_ok=True)

    binary_columns = (
        ["has_photo"]
        + sorted([c for c in df.columns if c.startswith("kw_")])
        + sorted([c for c in df.columns if c.startswith("tag_") and c not in {"tag_person_position"}])
        + sorted([c for c in df.columns if c.startswith("derived_")])
    )
    # deduplicate while preserving order
    seen = set()
    binary_columns = [c for c in binary_columns if not (c in seen or seen.add(c))]

    binary_summary = summarize_binary_features(df, binary_columns, "responder_goa")
    binary_path = report_dir / "goa_feature_binary_summary.csv"
    binary_summary.to_csv(binary_path, index=False)

    # frequency of true values for reference
    freq_records: List[dict] = []
    for col in binary_columns:
        series = to_bool(df[col])
        freq_records.append(
            {
                "feature": col,
                "count_true": int(series.sum()),
                "pct_true": series.mean() * 100 if len(series) else 0.0,
            }
        )
    freq_df = pd.DataFrame(freq_records)
    freq_df["label"] = freq_df["feature"].map(FEATURE_LABELS).fillna(freq_df["feature"])
    freq_df = freq_df.sort_values("pct_true", ascending=False)
    freq_df.to_csv(report_dir / "goa_feature_frequency.csv", index=False)

    numeric_specs = [
        ("desc_len", [0, 50, 100, 150, 250, 500, 1000, np.inf], None),
        ("tag_size_feet", [0, 1, 20, 50, 100, 200, np.inf], None),
        ("tag_num_people", [0, 1, 2, 3, 5, 10, np.inf], None),
    ]
    numeric_frames = []
    for column, bins, labels in numeric_specs:
        if column not in df.columns:
            continue
        numeric_frames.append(
            summarize_numeric_bins(df, column, bins, labels, "responder_goa")
        )
    numeric_summary = (
        pd.concat(numeric_frames, ignore_index=True)
        if numeric_frames
        else pd.DataFrame(columns=["feature", "bin_label", "count", "goa_count", "goa_rate_pct", "share_pct"])
    )
    numeric_path = report_dir / "goa_feature_numeric_bins.csv"
    numeric_summary.to_csv(numeric_path, index=False)

    raw_artifacts = [
        (report_dir / "goa_feature_binary_summary.csv", "Binary feature GOA rates and odds ratios"),
        (report_dir / "goa_feature_numeric_bins.csv", "Numeric feature GOA rates by bin"),
        (report_dir / "goa_feature_frequency.csv", "Feature prevalence (True share)"),
    ]

    feature_true = binary_summary[
        binary_summary["value"].astype(str).str.lower().eq("true")
    ].copy()
    feature_true = feature_true.sort_values("delta_pp", ascending=False)
    top_positive = feature_true.head(args.top_n)
    top_negative = feature_true.tail(args.top_n).sort_values("delta_pp")

    plot_entries: List[Tuple[str, str]] = []
    positive_plot = asset_dir / "goa_feature_positive.png"
    if maybe_bar_plot(top_positive, "Top positive GOA signals", positive_plot):
        plot_entries.append((rel_to_docs(positive_plot), "Top positive GOA signals"))
        raw_artifacts.append((positive_plot, "Top positive GOA signals chart"))
    negative_plot = asset_dir / "goa_feature_negative.png"
    if maybe_bar_plot(top_negative, "Largest negative GOA deltas", negative_plot):
        plot_entries.append((rel_to_docs(negative_plot), "Largest negative GOA deltas"))
        raw_artifacts.append((negative_plot, "Largest negative GOA deltas chart"))

    artifacts = []
    for path, desc in raw_artifacts:
        if path.exists():
            artifacts.append((rel_to_docs(path), desc))

    markdown = build_markdown(
        binary_summary,
        numeric_summary,
        df["responder_goa"].mean(),
        top_n=args.top_n,
        artifacts=artifacts,
        plots=plot_entries,
    )
    doc_path.parent.mkdir(parents=True, exist_ok=True)
    doc_path.write_text(markdown, encoding="utf-8")

    print(f"[goa-features] wrote summaries to {report_dir}")
    print(f"[goa-features] refreshed {doc_path}")


if __name__ == "__main__":
    main()
